{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plaque Barcoding pipeline**  \n",
    "Follow along our analysis steps and reproduce our results with the scripts below.  \n",
    "\n",
    "**Dependencies**\n",
    "* epicBarcoder (custom library on github)\n",
    "* pandas\n",
    "* pear\n",
    "* usearch v9.2\n",
    "* sina v1.2.11\n",
    "* fasttree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import epicBarcoder as eb\n",
    "from itertools import combinations\n",
    "from scipy.stats import poisson\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up personal computing environment with paths to necessary tools and data directories\n",
    "env = os.environ\n",
    "dataDir = '/home/ubuntu/users/sjspence/170214_OM8/04_jupyter/'\n",
    "pearPath = '/usr/local/bin/pear'\n",
    "usearchPath = '/home/ubuntu/users/sjspence/tools/usearch9.2.64_i86linux32'\n",
    "sinaPath = '/home/ubuntu/bin/sina-1.2.11/sina'\n",
    "fasttreePath = '/home/ubuntu/bin/FastTree_dd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import and edit mapping file\n",
    "sampIDs = []\n",
    "mapping = {}\n",
    "readCounts = {}\n",
    "with open(dataDir + 'OM8_map.txt', 'r') as inFile:\n",
    "    for line in inFile:\n",
    "        if '#' not in line:\n",
    "            line = line.strip().split('\\t')\n",
    "            mapping[line[1]] = line[0].replace('_','s')\n",
    "            readCounts[line[1]] = 0\n",
    "            sampIDs.append(line[0].replace('_','s'))\n",
    "inFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Join paired-end reads\n",
    "subprocess.call([pearPath, '-f', dataDir + '170214Alm_D17-2046_1_sequence.fastq', \n",
    "                 '-r', dataDir + '170214Alm_D17-2046_2_sequence.fastq', '-o', dataDir + '01_pear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71812424\n"
     ]
    }
   ],
   "source": [
    "#Break up file into pieces that usearch can use (5 million lines each)\n",
    "#Run this to completion before running next section\n",
    "inFile = open(dataDir + '01_pear.assembled.fastq', 'r')\n",
    "if not os.path.exists(dataDir + '02_pearSplits/'):\n",
    "    os.makedirs(dataDir + '02_pearSplits/')\n",
    "i = 0\n",
    "j = 1\n",
    "partFile = open(dataDir + '02_pearSplits/pear_' + str(j) + '.fastq', 'w')\n",
    "for line in inFile:\n",
    "    if i >= j*5000000:\n",
    "        partFile.close()\n",
    "        j += 1\n",
    "        partFile = open(dataDir + '02_pearSplits/pear_' + str(j) + '.fastq', 'w')\n",
    "    partFile.write(line)\n",
    "    i += 1\n",
    "partFile.close()\n",
    "inFile.close()\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Quality filter with usearch 9 max-error rate\n",
    "def qualFilter(inFile, outFile):\n",
    "    subprocess.call([usearchPath, \"-fastq_filter\", inFile, \"-fastq_minlen\", '100', '-fastq_maxee_rate', '0.01',\n",
    "                     \"-fastqout\", outFile], env=env)\n",
    "for filename in os.listdir(dataDir + '02_pearSplits/'):\n",
    "    qualFilter(dataDir + '02_pearSplits/' + filename, dataDir + '02_pearSplits/' + filename.replace('.fastq','filt.fastq'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Join quality-filtered files back into a single file for processing\n",
    "with open(dataDir + '02_pear_filt.fastq', 'w') as outfile:\n",
    "    for fname in os.listdir(dataDir + '02_pearSplits/'):\n",
    "        if 'filt' in fname:\n",
    "            with open(dataDir + '02_pearSplits/' + fname, 'r') as infile:\n",
    "                for line in infile:\n",
    "                    outfile.write(line)\n",
    "            infile.close()\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Demultiplex: check for barcodes and relabel sequences\n",
    "#Use mapping file to keep barcoded sequences, prepare fasta file\n",
    "with open(dataDir + '02_pear_filt.fastq', 'r') as inFile:\n",
    "    with open(dataDir + '03_pear_filt.fasta', 'w') as outFile:\n",
    "        i = 0\n",
    "        j = 0\n",
    "        nextSeq = False\n",
    "        for line in inFile:\n",
    "            if nextSeq:\n",
    "                outFile.write(line)\n",
    "                nextSeq = False\n",
    "            if i%4 == 0:\n",
    "                for bc in mapping:\n",
    "                    if bc in line:\n",
    "                        readCounts[bc] += 1\n",
    "                        newLine = line.strip().replace('@','>' + mapping[bc] + '_' + str(j) + ' ')\n",
    "                        newLine = newLine + ' orig_bc=' + bc + ' new_bc=' + bc + ' bc_diffs=0\\n'\n",
    "                        outFile.write(newLine)\n",
    "                        nextSeq = True\n",
    "                        j += 1\n",
    "            i += 1\n",
    "inFile.close()\n",
    "outFile.close()\n",
    "#Summarize read mapping after quality filtering and zero-error barcode matching\n",
    "total = 0\n",
    "summaryFile = open(dataDir + '03_quality_summary.txt', 'w')\n",
    "for s in sampIDs:\n",
    "    for bc in mapping:\n",
    "        if mapping[bc] == s:\n",
    "            summaryFile.write(s + '\\t' + str(readCounts[bc]) + '\\n')\n",
    "            total += readCounts[bc]\n",
    "summaryFile.write('Total\\t' + str(total))\n",
    "summaryFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Primer check and removal, placing droplet barcode into header\n",
    "#NOTE: this takes a while\n",
    "qualReads = eb.importFasta(dataDir + '03_pear_filt.fasta')\n",
    "noPrimerReads = eb.filtBarcodePrimers(qualReads, 20, 'GATCATGACCCATTTGGAGAAGATG', 'GGACTACHVGGGTWTCTAAT')\n",
    "eb.exportFasta(noPrimerReads, dataDir + '04_pear_noPrimers.fasta')\n",
    "print(len(qualReads))\n",
    "print(len(noPrimerReads))\n",
    "print(noPrimerReads[0].header)\n",
    "print(noPrimerReads[0].seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Collapse identical reads and maintain the provenance to reduce the uclust file size\n",
    "#uniqueDict maps a unique sequence to a list of read objects which contain it\n",
    "#NOTE: takes a long time, but rerun after notebook closes out\n",
    "noPrimerReads = eb.importFasta(dataDir + '04_pear_noPrimers.fasta')\n",
    "uniqueDict = eb.getUniqueSeqs(noPrimerReads, dataDir + '05_unique_seqs.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the usearch unoise algorithm to create zero radius OTUs (zOTUs), while also discarding chimeras, phiX sequences,\n",
    "#and low complexity DNA\n",
    "#Input: unique sequences collapsed from quality- and primer- filtered data\n",
    "#Output: Denoised file with true biological reads\n",
    "#        Database file with true amplicon reads including chimeras\n",
    "subprocess.call([usearchPath, '-unoise2', dataDir + '05_unique_seqs.fasta', '-fastaout', dataDir + '06_denoised.fa',\n",
    "                 '-otudbout', dataDir + '06_db.fa', '-minampsize', '3'], env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Unoise output**  \n",
    "00:02 332Mb   100.0% Reading 05_unique_seqs.fasta  \n",
    "00:04 352Mb   100.0% 3955 amplicons, 1791728 bad (size >= 3)\n",
    "01:55 359Mb   100.0% 354 good, 3601 chimeras\n",
    "\n",
    "46735 corrected amplicon sequences (including chimeras) in 06_db.fa  \n",
    "354 output biological sequences in 06_denoised.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOTE: Only need to do this once\n",
    "\n",
    "#Format fasta database for input to SINTAX\n",
    "#Maintained HOMD HOT strain ID in header following the taxonomic information\n",
    "#Example SINTAX header structure below:\n",
    "#>AB008314;tax=d:Bacteria,p:Firmicutes,c:Bacilli,o:Lactobacillales,f:Streptococcaceae,g:Streptococcus;\n",
    "outFile = open(dataDir + 'HOMD_16S_rRNA_RefSeq_V14.5.p9_sintax_spike.fasta', 'w')\n",
    "taxDict = {}\n",
    "with open(dataDir + 'HOMD_16S_rRNA_RefSeq_V14.5.qiime_spike.taxonomy', 'r') as t:\n",
    "    for line in t:\n",
    "        line = line.strip().split('\\t')\n",
    "        taxID = line[0]\n",
    "        tax = line[1].strip().replace('__',':')\n",
    "        tax = tax.replace(';',',')\n",
    "        taxDict[taxID] = tax\n",
    "with open(dataDir + 'HOMD_16S_rRNA_RefSeq_V14.5.p9_spike.fasta', 'r') as f:\n",
    "    for line in f:\n",
    "        if '>' in line:\n",
    "            line = line.strip().split(' ')\n",
    "            taxInfo = taxDict[line[0].replace('>','')]\n",
    "            outLine = line[0] + ';tax=' + taxInfo + ';'\n",
    "            for i in line:\n",
    "                if 'HOT' in i:\n",
    "                    outLine += i + ';'\n",
    "            outFile.write(outLine + '\\n')\n",
    "        else:\n",
    "            outFile.write(line)\n",
    "outFile.close()\n",
    "subprocess.call([usearchPath, '-makeudb_sintax', dataDir + 'HOMD_16S_rRNA_RefSeq_V14.5.p9_sintax_spike.fasta', \n",
    "                 '-output', dataDir + 'HOMD_16S_rRNA_RefSeq_V14.5.p9_sintax_spike.udb'], env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Database formatting output**  \n",
    "00:00 14Mb   1020 names, tax levels min 7, avg 7.0, max 7  \n",
    "WARNING: 25 taxonomy nodes have >1 parent  \n",
    "00:00 14Mb   Buffers (892 seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run SINTAX to determine denoised read taxonomic information\n",
    "#Default is to run one thread per CPU core, or 10 threads if there are > 10 cores\n",
    "subprocess.call([usearchPath, '-sintax', dataDir + '06_denoised.fa', \n",
    "                 '-db', dataDir + 'HOMD_16S_rRNA_RefSeq_V14.5.p9_sintax_spike.udb', \n",
    "                 '-tabbedout', dataDir + '07_denoised.sintax', \n",
    "                 '-strand', 'plus', '-sintax_cutoff', '0.8', '-threads', '4'], env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Combine taxonomic information to export final file with droplet barcodes and taxonomies\n",
    "#06_denoised.fa: header matches the first tabbed column of sintax output (minus '>'), sequence follows\n",
    "#Import list of read objects from unoise2 denoised file\n",
    "denoised = eb.importFasta(dataDir + '06_denoised.fa')\n",
    "\n",
    "#Import Otu header:[tax probabilities, taxonomy] dictionary from SINTAX output\n",
    "taxDict = eb.importSintax(dataDir + '07_denoised.sintax')\n",
    "\n",
    "#Take denoised zOTUs and taxonomic information, then map back to original reads and rewrite original read file with\n",
    "#zOTU and taxonomic information in the headers\n",
    "eb.otuToHeaders(denoised, taxDict, uniqueDict, dataDir + '08_all_seqs_tax.fa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read loss from unoise2**\n",
    "\n",
    "24490106 04_pear_noPrimers.fasta = 12,245,053 reads prior to unoise2  \n",
    "18228922 08_all_seqs_tax.fa = 9,114,461 reads after unoise2  \n",
    "\n",
    "Approximately 25% read loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Within each sample, group by barcode; quantify unique barcode pairings\n",
    "#Input: Fasta file with droplet barcode, otu, and taxonomic information in the header\n",
    "#Output: A dictionary where each sampID maps to a dictionary of droplet barcodes:[otu1, otu2]\n",
    "#        A dictionary where each OTU maps to a >80% taxonomy\n",
    "def createBarcodeDict(inFileName):\n",
    "    inFile = open(inFileName, 'r')\n",
    "    barcodeSamples = {}\n",
    "    taxDict = {}\n",
    "    for line in inFile:\n",
    "        if '>' in line:\n",
    "            line = line.strip().split(';')\n",
    "            samp = line[0].split('_')[0].replace('>','')\n",
    "            bc = line[0].split('droplet_bc=')[1]\n",
    "            otu = line[1]\n",
    "            tax = line[2].replace('tax=','')\n",
    "            if samp not in barcodeSamples:\n",
    "                barcodeSamples[samp] = {bc:[otu]}\n",
    "            else:\n",
    "                if bc not in barcodeSamples[samp]:\n",
    "                    barcodeSamples[samp][bc] = [otu]\n",
    "                else:\n",
    "                    barcodeSamples[samp][bc].append(otu)\n",
    "            if otu not in taxDict:\n",
    "                taxDict[otu] = tax\n",
    "    inFile.close()\n",
    "    return barcodeSamples, taxDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "barcodeDict, taxDict = createBarcodeDict(dataDir + '08_all_seqs_tax.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OM8s01\t31521\n",
      "OM8s02\t53460\n",
      "OM8s03\t39500\n",
      "OM8s04\t55974\n",
      "OM8s05\t42590\n",
      "OM8s06\t32403\n",
      "OM8s07\t41010\n",
      "OM8s08\t14979\n",
      "OM8s09\t26614\n",
      "OM8s10\t19314\n",
      "OM8s11\t49619\n",
      "OM8s12\t25415\n",
      "OM8s13\t24261\n",
      "OM8s14\t37860\n",
      "OM8s15\t5618\n",
      "OM8s16\t11338\n",
      "OM8s17\t69714\n",
      "OM8s18\t28819\n",
      "OM8s19\t40\n",
      "OM8s20\t82\n",
      "OM8s21\t221187\n",
      "OM8s22\t70931\n",
      "OM8s23\t85035\n",
      "OM8s24\t58186\n",
      "OM8s25\t145759\n",
      "OM8s26\t82787\n",
      "OM8s27\t7\n",
      "OM8s28\t29627\n",
      "OM8s29\t145\n",
      "OM8s30\t68\n",
      "OM8s31\t9\n",
      "OM8s32\t1\n",
      "OM8s34\t2\n"
     ]
    }
   ],
   "source": [
    "#Print number of barcodes per sample\n",
    "for s in sampIDs:\n",
    "    if s in barcodeDict:\n",
    "        sample = barcodeDict[s]\n",
    "        print(s + '\\t' + str(len(sample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Quantify unique pairings\n",
    "pairDicts = {}\n",
    "for s in sampIDs:\n",
    "    if s in barcodeDict:\n",
    "        uniquePairs = {}\n",
    "        for bc in barcodeDict[s]:\n",
    "            if len(barcodeDict[s][bc]) != 1:\n",
    "                uniqueOTUs = set(barcodeDict[s][bc])\n",
    "                if len(uniqueOTUs) != 1:\n",
    "                    pairString = '_'.join(list(uniqueOTUs))\n",
    "                    if pairString not in uniquePairs:\n",
    "                        uniquePairs[pairString] = 1\n",
    "                    else:\n",
    "                        uniquePairs[pairString] += 1\n",
    "        pairDicts[s] = uniquePairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate abundances of background OTUs based on singleton barcodes\n",
    "abundances = {}\n",
    "totals = {}\n",
    "for s in sampIDs:\n",
    "    if s not in barcodeDict:\n",
    "        continue\n",
    "    total = 0\n",
    "    backgroundOTU = {}\n",
    "    for bc in barcodeDict[s]:\n",
    "        if len(barcodeDict[s][bc]) == 1:\n",
    "            otu = barcodeDict[s][bc][0]\n",
    "            if otu not in backgroundOTU:\n",
    "                backgroundOTU[otu] = 1\n",
    "            else:\n",
    "                backgroundOTU[otu] += 1\n",
    "            total += 1\n",
    "    abundances[s] = backgroundOTU\n",
    "    totals[s] = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OM8s01: 11474\n",
      "OM8s02: 39245\n",
      "OM8s03: 30574\n",
      "OM8s04: 42100\n",
      "OM8s05: 27009\n",
      "OM8s06: 22064\n",
      "OM8s07: 36327\n",
      "OM8s08: 5744\n",
      "OM8s09: 13476\n",
      "OM8s10: 17249\n",
      "OM8s11: 43814\n",
      "OM8s12: 22287\n",
      "OM8s13: 19947\n",
      "OM8s14: 18799\n",
      "OM8s15: 3269\n",
      "OM8s16: 6909\n",
      "OM8s17: 51128\n",
      "OM8s18: 20161\n",
      "OM8s19: 32\n",
      "OM8s20: 72\n",
      "OM8s21: 127814\n",
      "OM8s22: 56249\n",
      "OM8s23: 59647\n",
      "OM8s24: 40453\n",
      "OM8s25: 95863\n",
      "OM8s26: 57738\n",
      "OM8s27: 6\n",
      "OM8s28: 14580\n",
      "OM8s29: 74\n",
      "OM8s30: 39\n",
      "OM8s31: 5\n",
      "OM8s32: 1\n",
      "OM8s34: 2\n"
     ]
    }
   ],
   "source": [
    "#Singleton counts for different samples\n",
    "for s in sampIDs:\n",
    "    if s in totals:\n",
    "        print(s + ': ' + str(totals[s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert abundance counts to relative abundances\n",
    "relAbundances = {}\n",
    "for s in sampIDs:\n",
    "    if s in abundances:\n",
    "        relAbund = {}\n",
    "        for otu in abundances[s]:\n",
    "            relAbund[otu] = float(abundances[s][otu]) / totals[s]\n",
    "        relAbundances[s] = relAbund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create dictionary mapping unique otu pairs to number of barcodes supporting it\n",
    "pairDict = {}\n",
    "for s in sampIDs:\n",
    "    if s not in barcodeDict:\n",
    "        continue\n",
    "    pairs = {}\n",
    "    for bc in barcodeDict[s]:\n",
    "        otuList = barcodeDict[s][bc]\n",
    "        if len(otuList) > 1:\n",
    "            uniqueOTUs = list(set(otuList))\n",
    "            if len(uniqueOTUs) > 1:\n",
    "                pairList = ['_'.join(list(comb)) for comb in combinations(uniqueOTUs, 2)]\n",
    "                for p in pairList:\n",
    "                    if p not in pairs:\n",
    "                        pairs[p] = 1\n",
    "                    else:\n",
    "                        pairs[p] += 1\n",
    "    pairDict[s] = pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OM8s01\t1311\t311\t68\t4\n",
      "OM8s02\t1109\t168\t59\t3\n",
      "OM8s03\t1132\t160\t47\t3\n",
      "OM8s04\t1506\t227\t70\t4\n",
      "OM8s05\t2466\t494\t102\t6\n",
      "OM8s06\t2445\t514\t84\t7\n",
      "OM8s07\t682\t291\t92\t1\n",
      "OM8s08\t1614\t403\t66\t1\n",
      "OM8s09\t462\t59\t2\t0\n",
      "OM8s10\t205\t67\t29\t1\n",
      "OM8s11\t1481\t311\t77\t1\n",
      "OM8s12\t940\t161\t36\t1\n",
      "OM8s13\t46\t18\t9\t8\n",
      "OM8s14\t15\t10\t4\t6\n",
      "OM8s15\t11\t2\t0\t2\n",
      "OM8s16\t13\t10\t4\t6\n",
      "OM8s17\t21\t14\t7\t7\n",
      "OM8s18\t13\t9\t3\t6\n",
      "OM8s19\t0\t0\t0\t0\n",
      "OM8s20\t0\t0\t0\t0\n",
      "OM8s21\t3462\t1682\t272\t11\n",
      "OM8s22\t734\t120\t30\t2\n",
      "OM8s23\t1420\t220\t67\t10\n",
      "OM8s24\t1737\t280\t67\t3\n",
      "OM8s25\t678\t135\t12\t1\n",
      "OM8s26\t1084\t242\t11\t1\n",
      "OM8s27\t0\t0\t0\t0\n",
      "OM8s28\t9\t6\t3\t1\n",
      "OM8s29\t3\t0\t0\t0\n",
      "OM8s30\t0\t0\t0\t0\n",
      "OM8s31\t0\t0\t0\t0\n",
      "OM8s32\t0\t0\t0\t0\n",
      "OM8s34\t0\t0\t0\t0\n"
     ]
    }
   ],
   "source": [
    "#Calculate poisson probabilities that two bugs would co-occur and filter results based on that\n",
    "#Print tab-delimited format showing total #pairs, #significant pairs, #shew to other, #shew to self\n",
    "cutoff = 0.00001\n",
    "for s in sampIDs:\n",
    "    if s not in pairDict:\n",
    "        continue\n",
    "    i = 0\n",
    "    t = 0\n",
    "    shew = 0\n",
    "    doubleShew = 0\n",
    "    for otuPair in pairDict[s]:\n",
    "        t += 1\n",
    "        otu1 = otuPair.split('_')[0]\n",
    "        otu2 = otuPair.split('_')[1]\n",
    "        if otu1 in relAbundances[s]:\n",
    "            a1 = relAbundances[s][otu1]\n",
    "        else:\n",
    "            a1 = 0.0\n",
    "        if otu2 in relAbundances[s]:\n",
    "            a2 = relAbundances[s][otu2]\n",
    "        else:\n",
    "            a2 = 0.0\n",
    "        x = pairDict[s][otuPair]\n",
    "        mu = a1 * a2 * totals[s]\n",
    "        p = poisson.pmf(x, mu)\n",
    "        if p < cutoff:\n",
    "            i += 1\n",
    "            if ('oneidensis' in taxDict[otu1]) and ('oneidensis' in taxDict[otu2]):\n",
    "                doubleShew += 1\n",
    "            elif ('oneidensis' in taxDict[otu1]) or ('oneidensis' in taxDict[otu2]):\n",
    "                shew += 1\n",
    "    print(s + '\\t' + str(t) + '\\t' + str(i) + '\\t' + str(shew) + '\\t' + str(doubleShew))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OM8s01\n",
      "Otu1\t0.0637092557086\n",
      "Otu55\t0.000435767822904\n",
      "Otu3\t0.046365696357\n",
      "Otu73\t0.000348614258323\n",
      "Otu183\t8.71535645808e-05\n",
      "\n",
      "\n",
      "OM8s02\n",
      "Otu73\t0.00119760479042\n",
      "Otu241\t7.64428589629e-05\n",
      "Otu55\t0.00211491909797\n",
      "Otu3\t0.173372404128\n",
      "Otu1\t0.243037329596\n",
      "Otu208\t5.09619059753e-05\n",
      "Otu217\t2.54809529876e-05\n",
      "Otu183\t0.000203847623901\n",
      "\n",
      "\n",
      "OM8s03\n",
      "Otu329\t3.27075292732e-05\n",
      "Otu73\t0.000425197880552\n",
      "Otu241\t6.54150585465e-05\n",
      "Otu55\t0.000981225878197\n",
      "Otu3\t0.0846797932884\n",
      "Otu1\t0.146562438673\n",
      "Otu217\t0.000130830117093\n",
      "Otu183\t0.000425197880552\n",
      "\n",
      "\n",
      "OM8s04\n",
      "Otu73\t0.000926365795724\n",
      "Otu241\t2.37529691211e-05\n",
      "Otu55\t0.00121140142518\n",
      "Otu3\t0.120831353919\n",
      "Otu1\t0.21945368171\n",
      "Otu183\t0.000475059382423\n",
      "\n",
      "\n",
      "OM8s05\n",
      "Otu73\t0.00159206190529\n",
      "Otu317\t3.70246954719e-05\n",
      "Otu241\t3.70246954719e-05\n",
      "Otu55\t0.00196230886001\n",
      "Otu3\t0.216039098078\n",
      "Otu1\t0.360842682069\n",
      "Otu276\t3.70246954719e-05\n",
      "Otu217\t0.000296197563775\n",
      "Otu183\t0.000333222259247\n",
      "\n",
      "\n",
      "OM8s06\n",
      "Otu338\t4.5322697607e-05\n",
      "Otu73\t0.000407904278463\n",
      "Otu55\t0.000634517766497\n",
      "Otu3\t0.194479695431\n",
      "Otu1\t0.340328136331\n",
      "Otu208\t0.000181290790428\n",
      "Otu217\t4.5322697607e-05\n",
      "Otu183\t9.06453952139e-05\n",
      "\n",
      "\n",
      "OM8s07\n",
      "Otu73\t0.000825832025766\n",
      "Otu55\t0.00129380350703\n",
      "Otu3\t0.049274644204\n",
      "Otu1\t0.17158036722\n",
      "\n",
      "\n",
      "OM8s08\n",
      "Otu3\t0.0997562674095\n",
      "Otu1\t0.171135097493\n",
      "Otu55\t0.000174094707521\n",
      "\n",
      "\n",
      "OM8s09\n",
      "Otu3\t0.00408132977145\n",
      "Otu1\t0.0117245473434\n",
      "\n",
      "\n",
      "OM8s10\n",
      "Otu73\t0.000463795002609\n",
      "Otu55\t0.000579743753261\n",
      "Otu3\t0.0571627340715\n",
      "Otu1\t0.182097512899\n",
      "\n",
      "\n",
      "OM8s11\n",
      "Otu73\t0.000524946364176\n",
      "Otu55\t0.00102706897339\n",
      "Otu3\t0.0289176975396\n",
      "Otu1\t0.0915460811613\n",
      "\n",
      "\n",
      "OM8s12\n",
      "Otu73\t0.000807645712747\n",
      "Otu55\t0.00215372190066\n",
      "Otu3\t0.0220756494818\n",
      "Otu1\t0.0771301655674\n",
      "\n",
      "\n",
      "OM8s13\n",
      "Otu3\t0.353687271269\n",
      "Otu1\t0.618940191507\n",
      "Otu73\t0.00561487943049\n",
      "Otu55\t0.0130846743871\n",
      "\n",
      "\n",
      "OM8s14\n",
      "Otu3\t0.396244481089\n",
      "Otu1\t0.596733868823\n",
      "Otu55\t0.00287249321772\n",
      "Otu73\t0.00117027501463\n",
      "\n",
      "\n",
      "OM8s15\n",
      "Otu3\t0.378097277455\n",
      "Otu73\t0.00122361578464\n",
      "Otu1\t0.607525237076\n",
      "Otu55\t0.00397675130009\n",
      "\n",
      "\n",
      "OM8s16\n",
      "Otu73\t0.00636850484875\n",
      "Otu3\t0.400057895499\n",
      "Otu1\t0.582139238674\n",
      "Otu55\t0.00593428860906\n",
      "\n",
      "\n",
      "OM8s17\n",
      "Otu3\t0.369503989986\n",
      "Otu1\t0.620286340166\n",
      "Otu73\t0.00291425442028\n",
      "Otu55\t0.00467454232514\n",
      "\n",
      "\n",
      "OM8s18\n",
      "Otu3\t0.342244928327\n",
      "Otu1\t0.65165418382\n",
      "Otu73\t0.00119041714201\n",
      "Otu55\t0.00203362928426\n",
      "\n",
      "\n",
      "OM8s19\n",
      "Otu1\t0.03125\n",
      "Otu55\t0.09375\n",
      "Otu3\t0.0625\n",
      "\n",
      "\n",
      "OM8s20\n",
      "Otu73\t0.152777777778\n",
      "Otu55\t0.180555555556\n",
      "\n",
      "\n",
      "OM8s21\n",
      "Otu338\t7.82386905973e-06\n",
      "Otu73\t0.000711972084435\n",
      "Otu55\t0.00107969393024\n",
      "Otu3\t0.0381726571424\n",
      "Otu1\t0.0646251584333\n",
      "Otu276\t7.82386905973e-06\n",
      "\n",
      "\n",
      "OM8s22\n",
      "Otu3\t0.0720368362104\n",
      "Otu1\t0.112197550179\n",
      "Otu73\t0.000373339970488\n",
      "Otu329\t1.77780938328e-05\n",
      "Otu317\t1.77780938328e-05\n",
      "Otu55\t0.000835570410141\n",
      "\n",
      "\n",
      "OM8s23\n",
      "Otu329\t1.67653025299e-05\n",
      "Otu73\t0.00110650996697\n",
      "Otu55\t0.0014585813201\n",
      "Otu3\t0.0916726742334\n",
      "Otu1\t0.13737488893\n",
      "Otu276\t1.67653025299e-05\n",
      "\n",
      "\n",
      "OM8s24\n",
      "Otu3\t0.118977578919\n",
      "Otu73\t0.000840481546486\n",
      "Otu1\t0.21078782785\n",
      "Otu55\t0.0018045633204\n",
      "Otu276\t4.94400909698e-05\n",
      "\n",
      "\n",
      "OM8s25\n",
      "Otu3\t0.00174206941156\n",
      "Otu1\t0.00659274172517\n",
      "Otu55\t1.04315533626e-05\n",
      "\n",
      "\n",
      "OM8s26\n",
      "Otu3\t0.0185146697149\n",
      "Otu1\t0.0371852159756\n",
      "Otu73\t8.65980809865e-05\n",
      "Otu55\t6.92784647892e-05\n",
      "\n",
      "\n",
      "OM8s27\n",
      "Otu3\t0.166666666667\n",
      "Otu1\t0.333333333333\n",
      "\n",
      "\n",
      "OM8s28\n",
      "Otu3\t0.0699588477366\n",
      "Otu1\t0.100342935528\n",
      "\n",
      "\n",
      "OM8s29\n",
      "Otu3\t0.108108108108\n",
      "Otu1\t0.391891891892\n",
      "\n",
      "\n",
      "OM8s30\n",
      "Otu3\t0.25641025641\n",
      "Otu1\t0.487179487179\n",
      "\n",
      "\n",
      "OM8s31\n",
      "Otu1\t0.6\n",
      "\n",
      "\n",
      "OM8s32\n",
      "\n",
      "\n",
      "OM8s33\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'OM8s33'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-5ca18c083611>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msampIDs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0motu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrelAbundances\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'oneidensis'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtaxDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0motu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0motu\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\t'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrelAbundances\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0motu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'OM8s33'"
     ]
    }
   ],
   "source": [
    "#What are the s. oneidensis relative abundances?\n",
    "for s in sampIDs:\n",
    "    print(s)\n",
    "    for otu in relAbundances[s]:\n",
    "        if 'oneidensis' in taxDict[otu]:\n",
    "            print(otu + '\\t' + str(relAbundances[s][otu]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES: OK shewanella was divided into a bunch of OTUs, so probably makes sense to combine them for analysis.  This will likely increase the rel. abundance of S. oneidensis and reduce the significant connections in our poisson model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try cluster_fast clustering\n",
    "subprocess.call([usearchPath, '-cluster_fast', dataDir + '06_denoised.fa', '-id', '0.97', '-centroids', \n",
    "                dataDir + '09_otu_clusters.fa', '-uc', dataDir + '09_otu_clusters.uc'], env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      Seqs  354  \n",
    "  Clusters  154  \n",
    "  Max size  17  \n",
    "  Avg size  2.3  \n",
    "  Min size  1  \n",
    "Singletons  74, 20.9% of seqs, 48.1% of clusters  \n",
    "   Max mem  83Mb  \n",
    "      Time  1.00s  \n",
    "Throughput  354.0 seqs/sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import list of read objects from unoise2 denoised file\n",
    "denoised = eb.importFasta(dataDir + '06_denoised.fa')\n",
    "\n",
    "#Import Otu header:[tax probabilities, taxonomy] dictionary from SINTAX output\n",
    "taxDict = eb.importSintax(dataDir + '07_denoised.sintax')\n",
    "\n",
    "#Import hits from 97% fast clustering\n",
    "hits = eb.importClusterFast(dataDir + '09_otu_clusters.uc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otu6;uniq=OM8s21_7\n",
      "['k:Bacteria(1.0000),p:Fusobacteria(1.0000),c:Fusobacteriia(1.0000),o:Fusobacteriales(1.0000),f:Fusobacteriaceae(1.0000),g:Fusobacterium(1.0000),s:nucleatum_subsp._polymorphum(0.7700)', 'k:Bacteria,p:Fusobacteria,c:Fusobacteriia,o:Fusobacteriales,f:Fusobacteriaceae,g:Fusobacterium']\n"
     ]
    }
   ],
   "source": [
    "#FIRST TRY TO SEE HOW MUCH SHEWANELLA COLLAPSES BY TAXONOMY\n",
    "i = 0\n",
    "for t in taxDict:\n",
    "    if i == 0:\n",
    "        print(t)\n",
    "        print(taxDict[t])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otu111;uniq=OM8s08_7689 HWI-M04407:1:2105:24185:5342#TCTGTATG/1 orig_bc=TCTGTATG new_bc=TCTGTATG bc_diffs=0 droplet_bc=TTTGCCTTGAGCAGAGAACA;size=1956;\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#Check number of shewanella seqs in 97% otu clusters\n",
    "i = 0\n",
    "j = 0\n",
    "shewSeqs = []\n",
    "for h in hits:\n",
    "    if j == 0:\n",
    "        print(h)\n",
    "    j += 1\n",
    "    seqID = h.split(' ')[0]\n",
    "    if 'oneidensis' in taxDict[seqID][1]:\n",
    "        i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "shewReads = []\n",
    "for read in denoised:\n",
    "    if (read.header.replace('>','') in hits) and ('Shew' in taxDict[read.seq_id][1]):\n",
    "        shewReads.append(read)\n",
    "print(len(shewReads))\n",
    "eb.exportFasta(shewReads, dataDir + 'multiple_shew_97_otus.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354\n",
      "10\n",
      "5\n",
      "4\n",
      "7\n",
      "88\n",
      "233\n"
     ]
    }
   ],
   "source": [
    "#How many taxonomic indications map all the way to species?  Can I make a taxonomy OTU table?\n",
    "total = 0\n",
    "phylum = 0\n",
    "clas = 0\n",
    "order = 0\n",
    "family = 0\n",
    "genus = 0\n",
    "species = 0\n",
    "for t in taxDict:\n",
    "    total += 1\n",
    "    if 's:' in taxDict[t][1]:\n",
    "        species +=1\n",
    "    elif 'g:' in taxDict[t][1]:\n",
    "        genus += 1\n",
    "    elif 'f:' in taxDict[t][1]:\n",
    "        family += 1\n",
    "    elif 'o:' in taxDict[t][1]:\n",
    "        order += 1\n",
    "    elif 'c:' in taxDict[t][1]:\n",
    "        clas += 1\n",
    "    elif 'p:' in taxDict[t][1]:\n",
    "        phylum += 1\n",
    "print(total)\n",
    "print(phylum)\n",
    "print(clas)\n",
    "print(order)\n",
    "print(family)\n",
    "print(genus)\n",
    "print(species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For every taxonomic assignment, choose the most abundant representative sequence\n",
    "#Build a pandas OTU table\n",
    "taxOTUs = {}\n",
    "for read in denoised:\n",
    "    if \n",
    "    \n",
    "    \n",
    "    if (read.header.replace('>','') in hits) and ('Shew' in taxDict[read.seq_id][1]):\n",
    "        shewReads.append(read)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.5",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
